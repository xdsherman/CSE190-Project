{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name:\n",
    "#### Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 190 Project\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.io import wavfile\n",
    "from numpy.linalg import svd\n",
    "from scipy.stats.mstats import gmean\n",
    "from matplotlib import rcParams\n",
    "import scipy\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "from music21 import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.layers import ReLU\n",
    "from keras.layers import Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import categorical_crossentropy\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose all the midi files into key of C major or A minor\n",
    "\n",
    "reference: https://gist.github.com/aldous-rey/68c6c43450517aa47474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# major conversions\n",
    "majors = dict([(\"A-\", 4),(\"A\", 3),(\"B-\", 2),(\"B\", 1),(\"C\", 0),(\"D-\", -1),(\"D\", -2),(\"E-\", -3),(\"E\", -4),(\"F\", -5),(\"G-\", 6),(\"G\", 5)])\n",
    "minors = dict([(\"A-\", 1),(\"A\", 0),(\"B-\", -1),(\"B\", -2),(\"C\", -3),(\"D-\", -4),(\"D\", -5),(\"E-\", 6),(\"E\", 5),(\"F\", 4),(\"G-\", 3),(\"G\", 2)])\n",
    "\n",
    "\n",
    "#os.chdir(\"./\")\n",
    "for file in glob.glob(\"mozart_piano_sonata/*.mid\"):\n",
    "    midi = converter.parse(file)\n",
    "    key = midi.analyze('key')\n",
    "    file=file[file.find(\"\\\\\")+1:len(file)-4]\n",
    "#    print key.tonic.name, key.mode\n",
    "    if key.mode == \"major\":\n",
    "        halfSteps = majors[key.tonic.name]\n",
    "        \n",
    "    elif key.mode == \"minor\":\n",
    "        halfSteps = minors[key.tonic.name]\n",
    "    \n",
    "    midi = midi.transpose(halfSteps)\n",
    "    midi.write('midi',fp='transpose/{0}_transpose.mid'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    \n",
    "    ''' Your Code Here '''\n",
    "    model.add(LSTM(512,recurrent_dropout=0.3))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Lambda(lambda x: x / 0.6))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After parsing the midi files into musi21 stream, if the element is a note element, get the pitch name and duration, and encoded in the format {pitchname} _ {note duration}. If the element is a chord element, encode in normal chord form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "\n",
    "    notes = []\n",
    "    for file in glob.glob(\"transpose/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        print(\"Parsing %s\" % file)\n",
    "        notes_to_parse = None\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch)+'_'+str(element.duration.quarterLength))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "            #print(element)\n",
    "            #print(notes)\n",
    "    pickle.dump(notes, open('notes.p', 'wb'))\n",
    "    #print(notes)\n",
    "    return notes\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 4 \n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    #print(pitchnames)\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    #print(note_to_int)\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    #print(notes)\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        #print('in',i,sequence_in)\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        #print('out',i,sequence_out)\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "    #print(network_input)\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    #print(network_input)\n",
    "\n",
    "    return (network_input, network_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network 50 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes()\n",
    "\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab)\n",
    " \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"weights2-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\",\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # Your line of code here\n",
    "    model.fit(x=network_input,y=network_output,callbacks=callbacks_list,epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did the training in another file so here is an error. The weighting I used below is the weighting I got from training in another ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-6fd1a7e30b9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_network' is not defined"
     ]
    }
   ],
   "source": [
    "train_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_prediction(notes, pitchnames, n_vocab):\n",
    "\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    sequence_length = 4\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "        \n",
    "    print(note_to_int)\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)\n",
    "\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    for note_index in range(200):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        \n",
    "        ### Complete the line below\n",
    "        prediction = model.predict(prediction_input)\n",
    "        #print(prediction)\n",
    "        index = np.argmax(prediction)\n",
    "        #print(index)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    notes = pickle.load(open('notes.p', 'rb'))\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences_prediction(notes, pitchnames, n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    #model.save_weights('weight')\n",
    "    ### Add a line to load the weights here\n",
    "    model.load_weights('weights2-improvement-50-4.3253-bigger.hdf5')\n",
    "    \n",
    "    \n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create midi files by coverting string back to midi notes. Offset are set as the duration of notes that are predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '0.1': 1, '0.2': 2, '0.2.5': 3, '0.2.5.7': 4, '0.2.6': 5, '0.2.7': 6, '0.3': 7, '0.3.6': 8, '0.3.6.9': 9, '0.3.7': 10, '0.4': 11, '0.4.5': 12, '0.4.5.7': 13, '0.4.7': 14, '0.5': 15, '0.6': 16, '1': 17, '1.2': 18, '1.2.6': 19, '1.3': 20, '1.4': 21, '1.4.7': 22, '1.4.7.10': 23, '1.4.7.9': 24, '1.5': 25, '1.7': 26, '10': 27, '10.0': 28, '10.0.4': 29, '10.1': 30, '10.1.3': 31, '10.1.4': 32, '10.2': 33, '10.2.4': 34, '10.2.5': 35, '10.3': 36, '11': 37, '11.0': 38, '11.0.2': 39, '11.0.2.4': 40, '11.1': 41, '11.1.5': 42, '11.2': 43, '11.2.4': 44, '11.2.4.7': 45, '11.2.5': 46, '11.2.5.7': 47, '11.3': 48, '11.4': 49, '2': 50, '2.3': 51, '2.4': 52, '2.4.5': 53, '2.4.7': 54, '2.4.8': 55, '2.5': 56, '2.5.7': 57, '2.5.8': 58, '2.5.8.10': 59, '2.5.8.11': 60, '2.5.9': 61, '2.6': 62, '2.6.9': 63, '2.7': 64, '2.8': 65, '3': 66, '3.5': 67, '3.5.9': 68, '3.6': 69, '3.6.9': 70, '3.7': 71, '3.7.10': 72, '3.7.9': 73, '3.8': 74, '3.9': 75, '4': 76, '4.10': 77, '4.5': 78, '4.6': 79, '4.7': 80, '4.7.10': 81, '4.7.10.0': 82, '4.7.11': 83, '4.7.9': 84, '4.8': 85, '4.8.11': 86, '4.9': 87, '5': 88, '5.10': 89, '5.11': 90, '5.7': 91, '5.7.0': 92, '5.7.10': 93, '5.7.11': 94, '5.7.9.11': 95, '5.8': 96, '5.8.0': 97, '5.8.10': 98, '5.8.11': 99, '5.9': 100, '5.9.0': 101, '5.9.11': 102, '6': 103, '6.11': 104, '6.7': 105, '6.9': 106, '6.9.0': 107, '6.9.0.2': 108, '6.9.11': 109, '7': 110, '7.0': 111, '7.10': 112, '7.10.0': 113, '7.10.1': 114, '7.10.2': 115, '7.11': 116, '7.11.2': 117, '7.8': 118, '7.9': 119, '7.9.0': 120, '7.9.1': 121, '7.9.10': 122, '7.9.2': 123, '8': 124, '8.0': 125, '8.0.2': 126, '8.0.3': 127, '8.10.11': 128, '8.10.2': 129, '8.11': 130, '8.11.2': 131, '8.11.2.4': 132, '8.11.3': 133, '8.9': 134, '8.9.0': 135, '9': 136, '9.0': 137, '9.0.2': 138, '9.0.3': 139, '9.0.4': 140, '9.1': 141, '9.1.4': 142, '9.10': 143, '9.11': 144, '9.11.0': 145, '9.11.2.4': 146, '9.11.2.5': 147, '9.11.3': 148, '9.2': 149, 'A1_0.25': 150, 'A1_0.5': 151, 'A1_1.0': 152, 'A1_1.5': 153, 'A1_1/3': 154, 'A1_120.0': 155, 'A1_27.25': 156, 'A1_3.0': 157, 'A1_63.75': 158, 'A1_97/3': 159, 'A2_0.25': 160, 'A2_0.5': 161, 'A2_0.75': 162, 'A2_1.0': 163, 'A2_1.5': 164, 'A2_1/3': 165, 'A2_12.5': 166, 'A2_2.0': 167, 'A2_2.75': 168, 'A2_27.5': 169, 'A2_28/3': 170, 'A2_41.25': 171, 'A2_5.0': 172, 'A2_7.0': 173, 'A2_86.25': 174, 'A3_0.0': 175, 'A3_0.25': 176, 'A3_0.5': 177, 'A3_0.75': 178, 'A3_1.0': 179, 'A3_1.25': 180, 'A3_1.5': 181, 'A3_1.75': 182, 'A3_1/3': 183, 'A3_10.0': 184, 'A3_10/3': 185, 'A3_11.25': 186, 'A3_12.25': 187, 'A3_12.5': 188, 'A3_13.0': 189, 'A3_130.0': 190, 'A3_14.5': 191, 'A3_15.25': 192, 'A3_150.0': 193, 'A3_158.75': 194, 'A3_16/3': 195, 'A3_2.0': 196, 'A3_2.5': 197, 'A3_2/3': 198, 'A3_20.25': 199, 'A3_21.0': 200, 'A3_211.5': 201, 'A3_25.75': 202, 'A3_26.0': 203, 'A3_27.25': 204, 'A3_28.25': 205, 'A3_29.0': 206, 'A3_3.0': 207, 'A3_3.25': 208, 'A3_33.75': 209, 'A3_35.25': 210, 'A3_36.0': 211, 'A3_4.0': 212, 'A3_4.25': 213, 'A3_4.75': 214, 'A3_41/3': 215, 'A3_44/3': 216, 'A3_5.75': 217, 'A3_52.25': 218, 'A3_56.0': 219, 'A3_59.75': 220, 'A3_6.0': 221, 'A3_6.25': 222, 'A3_7.5': 223, 'A3_7.75': 224, 'A3_8.0': 225, 'A3_82/3': 226, 'A3_97/3': 227, 'A4_0.0': 228, 'A4_0.25': 229, 'A4_0.5': 230, 'A4_0.75': 231, 'A4_1.0': 232, 'A4_1.25': 233, 'A4_1.5': 234, 'A4_1.75': 235, 'A4_1/3': 236, 'A4_10.0': 237, 'A4_10.25': 238, 'A4_10.5': 239, 'A4_10.75': 240, 'A4_10/3': 241, 'A4_11.0': 242, 'A4_11.25': 243, 'A4_11/3': 244, 'A4_12.0': 245, 'A4_12.75': 246, 'A4_13.0': 247, 'A4_13.75': 248, 'A4_14.25': 249, 'A4_140/3': 250, 'A4_142/3': 251, 'A4_15.0': 252, 'A4_15.5': 253, 'A4_16.0': 254, 'A4_16.5': 255, 'A4_17.25': 256, 'A4_17.5': 257, 'A4_18.0': 258, 'A4_18.5': 259, 'A4_18.75': 260, 'A4_19.25': 261, 'A4_19.75': 262, 'A4_2.0': 263, 'A4_2.25': 264, 'A4_2.5': 265, 'A4_2.75': 266, 'A4_2/3': 267, 'A4_20.25': 268, 'A4_20/3': 269, 'A4_21.75': 270, 'A4_22.0': 271, 'A4_22.5': 272, 'A4_22/3': 273, 'A4_24.75': 274, 'A4_25.25': 275, 'A4_26/3': 276, 'A4_263/3': 277, 'A4_27.5': 278, 'A4_28.75': 279, 'A4_29.0': 280, 'A4_3.0': 281, 'A4_3.25': 282, 'A4_3.5': 283, 'A4_3.75': 284, 'A4_30.75': 285, 'A4_33.0': 286, 'A4_35/3': 287, 'A4_37.5': 288, 'A4_4.0': 289, 'A4_4.25': 290, 'A4_4.5': 291, 'A4_4.75': 292, 'A4_4/3': 293, 'A4_42.0': 294, 'A4_44/3': 295, 'A4_47.75': 296, 'A4_49.0': 297, 'A4_5.0': 298, 'A4_5.25': 299, 'A4_5.5': 300, 'A4_5.75': 301, 'A4_5/3': 302, 'A4_53/3': 303, 'A4_59.75': 304, 'A4_6.0': 305, 'A4_6.25': 306, 'A4_6.5': 307, 'A4_6.75': 308, 'A4_69.75': 309, 'A4_7.0': 310, 'A4_7.25': 311, 'A4_7.5': 312, 'A4_7.75': 313, 'A4_72.5': 314, 'A4_78.5': 315, 'A4_8.0': 316, 'A4_9.25': 317, 'A4_9.5': 318, 'A4_9.75': 319, 'A5_0.0': 320, 'A5_0.25': 321, 'A5_0.5': 322, 'A5_0.75': 323, 'A5_1.0': 324, 'A5_1.25': 325, 'A5_1.5': 326, 'A5_1.75': 327, 'A5_1/3': 328, 'A5_10.0': 329, 'A5_10/3': 330, 'A5_107.0': 331, 'A5_11.0': 332, 'A5_11.75': 333, 'A5_11/3': 334, 'A5_12.0': 335, 'A5_12.75': 336, 'A5_13.0': 337, 'A5_13.75': 338, 'A5_14.75': 339, 'A5_15.0': 340, 'A5_15.5': 341, 'A5_17.25': 342, 'A5_18.25': 343, 'A5_19.0': 344, 'A5_19.75': 345, 'A5_2.0': 346, 'A5_2.25': 347, 'A5_2.5': 348, 'A5_2.75': 349, 'A5_2/3': 350, 'A5_20.25': 351, 'A5_20.5': 352, 'A5_22.0': 353, 'A5_24.0': 354, 'A5_25.0': 355, 'A5_25/3': 356, 'A5_27.75': 357, 'A5_29.5': 358, 'A5_3.0': 359, 'A5_3.25': 360, 'A5_3.5': 361, 'A5_3.75': 362, 'A5_30.5': 363, 'A5_31.25': 364, 'A5_32.75': 365, 'A5_34/3': 366, 'A5_4.0': 367, 'A5_4.25': 368, 'A5_4.5': 369, 'A5_4.75': 370, 'A5_4/3': 371, 'A5_41.0': 372, 'A5_44.0': 373, 'A5_5.0': 374, 'A5_5.25': 375, 'A5_5.5': 376, 'A5_5.75': 377, 'A5_5/3': 378, 'A5_54.5': 379, 'A5_6.0': 380, 'A5_6.25': 381, 'A5_6.5': 382, 'A5_6.75': 383, 'A5_68.0': 384, 'A5_7.0': 385, 'A5_7.25': 386, 'A5_7.75': 387, 'A5_7/3': 388, 'A5_8.0': 389, 'A5_8.25': 390, 'A5_8.5': 391, 'A5_8.75': 392, 'A5_80.5': 393, 'A5_9.0': 394, 'A5_91/3': 395, 'A6_0.25': 396, 'A6_0.5': 397, 'A6_1.0': 398, 'A6_1/3': 399, 'A6_101.75': 400, 'B-1_0.25': 401, 'B-1_1.0': 402, 'B-1_2.5': 403, 'B-2_0.25': 404, 'B-2_0.5': 405, 'B-2_1.0': 406, 'B-2_1.5': 407, 'B-2_1/3': 408, 'B-2_2.0': 409, 'B-3_0.0': 410, 'B-3_0.25': 411, 'B-3_0.5': 412, 'B-3_0.75': 413, 'B-3_1.0': 414, 'B-3_1.25': 415, 'B-3_1/3': 416, 'B-3_2.0': 417, 'B-3_2.5': 418, 'B-3_246.25': 419, 'B-3_3.0': 420, 'B-3_3.75': 421, 'B-3_42.0': 422, 'B-3_5.75': 423, 'B-3_7.25': 424, 'B-4_0.0': 425, 'B-4_0.25': 426, 'B-4_0.5': 427, 'B-4_0.75': 428, 'B-4_1.0': 429, 'B-4_1.25': 430, 'B-4_1.5': 431, 'B-4_1.75': 432, 'B-4_1/3': 433, 'B-4_10.0': 434, 'B-4_10/3': 435, 'B-4_107.25': 436, 'B-4_110/3': 437, 'B-4_16.0': 438, 'B-4_16.75': 439, 'B-4_164/3': 440, 'B-4_17.25': 441, 'B-4_17.75': 442, 'B-4_2.0': 443, 'B-4_2.25': 444, 'B-4_2.5': 445, 'B-4_2/3': 446, 'B-4_20.25': 447, 'B-4_24.0': 448, 'B-4_25.5': 449, 'B-4_27.25': 450, 'B-4_3.0': 451, 'B-4_3.5': 452, 'B-4_34/3': 453, 'B-4_38.5': 454, 'B-4_4.25': 455, 'B-4_4/3': 456, 'B-4_40.25': 457, 'B-4_42.25': 458, 'B-4_50.5': 459, 'B-4_6.25': 460, 'B-4_7.0': 461, 'B-4_72.5': 462, 'B-4_8.75': 463, 'B-4_81.25': 464, 'B-4_9.0': 465, 'B-4_90.0': 466, 'B-4_92.75': 467, 'B-4_97.25': 468, 'B-5_0.0': 469, 'B-5_0.25': 470, 'B-5_0.5': 471, 'B-5_0.75': 472, 'B-5_1.0': 473, 'B-5_1.25': 474, 'B-5_1.5': 475, 'B-5_1.75': 476, 'B-5_1/3': 477, 'B-5_101/3': 478, 'B-5_11.0': 479, 'B-5_13.0': 480, 'B-5_2.0': 481, 'B-5_2.25': 482, 'B-5_2.75': 483, 'B-5_29.5': 484, 'B-5_3.0': 485, 'B-5_3.5': 486, 'B-5_305.0': 487, 'B-5_31.0': 488, 'B-5_39.75': 489, 'B-5_45.5': 490, 'B-5_5.0': 491, 'B-5_61.5': 492, 'B-5_63.25': 493, 'B-5_86.5': 494, 'B-6_0.25': 495, 'B-6_0.5': 496, 'B1_0.25': 497, 'B1_0.5': 498, 'B1_1.0': 499, 'B1_1.25': 500, 'B1_113/3': 501, 'B1_12.0': 502, 'B1_14.75': 503, 'B2_0.25': 504, 'B2_0.5': 505, 'B2_0.75': 506, 'B2_1.0': 507, 'B2_1.25': 508, 'B2_1/3': 509, 'B2_119.75': 510, 'B2_13.0': 511, 'B2_15.0': 512, 'B2_18.75': 513, 'B2_19.75': 514, 'B2_2.0': 515, 'B2_3.75': 516, 'B2_30.0': 517, 'B2_4.0': 518, 'B2_4.75': 519, 'B2_42.75': 520, 'B2_43.5': 521, 'B2_49.25': 522, 'B2_5.0': 523, 'B2_6.25': 524, 'B2_6.5': 525, 'B2_6.75': 526, 'B3_0.0': 527, 'B3_0.25': 528, 'B3_0.5': 529, 'B3_0.75': 530, 'B3_1.0': 531, 'B3_1.25': 532, 'B3_1.5': 533, 'B3_1.75': 534, 'B3_1/3': 535, 'B3_101/3': 536, 'B3_11.5': 537, 'B3_119.75': 538, 'B3_12.0': 539, 'B3_12.75': 540, 'B3_13.5': 541, 'B3_14.0': 542, 'B3_14.5': 543, 'B3_141.75': 544, 'B3_15.5': 545, 'B3_16.5': 546, 'B3_17.75': 547, 'B3_18.0': 548, 'B3_18.25': 549, 'B3_19.0': 550, 'B3_2.0': 551, 'B3_2.5': 552, 'B3_2.75': 553, 'B3_21.25': 554, 'B3_21.5': 555, 'B3_22/3': 556, 'B3_225.0': 557, 'B3_23.25': 558, 'B3_26.25': 559, 'B3_27.5': 560, 'B3_3.0': 561, 'B3_3.25': 562, 'B3_3.5': 563, 'B3_3.75': 564, 'B3_30.0': 565, 'B3_30.25': 566, 'B3_33.0': 567, 'B3_4.0': 568, 'B3_4.5': 569, 'B3_42.5': 570, 'B3_48.0': 571, 'B3_5.0': 572, 'B3_5.5': 573, 'B3_50/3': 574, 'B3_54.0': 575, 'B3_6.0': 576, 'B3_6.25': 577, 'B3_8.0': 578, 'B3_8.5': 579, 'B3_9.25': 580, 'B3_9.75': 581, 'B4_0.0': 582, 'B4_0.25': 583, 'B4_0.5': 584, 'B4_0.75': 585, 'B4_1.0': 586, 'B4_1.25': 587, 'B4_1.5': 588, 'B4_1.75': 589, 'B4_1/3': 590, 'B4_10.0': 591, 'B4_10.25': 592, 'B4_10.5': 593, 'B4_10.75': 594, 'B4_10/3': 595, 'B4_11.0': 596, 'B4_11.25': 597, 'B4_11.5': 598, 'B4_11.75': 599, 'B4_11/3': 600, 'B4_12.0': 601, 'B4_12.25': 602, 'B4_12.75': 603, 'B4_13.75': 604, 'B4_13/3': 605, 'B4_14.0': 606, 'B4_14.75': 607, 'B4_15.0': 608, 'B4_15.25': 609, 'B4_16.0': 610, 'B4_16.25': 611, 'B4_17.25': 612, 'B4_17.75': 613, 'B4_17/3': 614, 'B4_19.0': 615, 'B4_2.0': 616, 'B4_2.25': 617, 'B4_2.5': 618, 'B4_2.75': 619, 'B4_2/3': 620, 'B4_20.25': 621, 'B4_20.75': 622, 'B4_20/3': 623, 'B4_21.25': 624, 'B4_21.5': 625, 'B4_22.5': 626, 'B4_23/3': 627, 'B4_28/3': 628, 'B4_29.25': 629, 'B4_3.0': 630, 'B4_3.25': 631, 'B4_3.5': 632, 'B4_3.75': 633, 'B4_30.75': 634, 'B4_31/3': 635, 'B4_32.75': 636, 'B4_33.0': 637, 'B4_33.75': 638, 'B4_37/3': 639, 'B4_4.0': 640, 'B4_4.25': 641, 'B4_4.5': 642, 'B4_4.75': 643, 'B4_43.0': 644, 'B4_44.0': 645, 'B4_44/3': 646, 'B4_5.0': 647, 'B4_5.25': 648, 'B4_5.5': 649, 'B4_5.75': 650, 'B4_55/3': 651, 'B4_6.0': 652, 'B4_6.25': 653, 'B4_6.5': 654, 'B4_6.75': 655, 'B4_61.0': 656, 'B4_7.0': 657, 'B4_7.25': 658, 'B4_7.5': 659, 'B4_7.75': 660, 'B4_7/3': 661, 'B4_73.5': 662, 'B4_8.0': 663, 'B4_8.5': 664, 'B4_8.75': 665, 'B4_83.25': 666, 'B4_9.0': 667, 'B4_9.25': 668, 'B4_9.5': 669, 'B4_9.75': 670, 'B4_94/3': 671, 'B5_0.0': 672, 'B5_0.25': 673, 'B5_0.5': 674, 'B5_0.75': 675, 'B5_1.0': 676, 'B5_1.25': 677, 'B5_1.5': 678, 'B5_1.75': 679, 'B5_1/3': 680, 'B5_10.0': 681, 'B5_10.25': 682, 'B5_10.5': 683, 'B5_10.75': 684, 'B5_10/3': 685, 'B5_11.25': 686, 'B5_12.0': 687, 'B5_12.25': 688, 'B5_13.75': 689, 'B5_14.5': 690, 'B5_148.75': 691, 'B5_16.0': 692, 'B5_16.5': 693, 'B5_160.5': 694, 'B5_17.5': 695, 'B5_18.0': 696, 'B5_184/3': 697, 'B5_19.0': 698, 'B5_19.5': 699, 'B5_2.0': 700, 'B5_2.25': 701, 'B5_2.5': 702, 'B5_2.75': 703, 'B5_2/3': 704, 'B5_20/3': 705, 'B5_205/3': 706, 'B5_21.5': 707, 'B5_22.0': 708, 'B5_24.25': 709, 'B5_24.5': 710, 'B5_25.0': 711, 'B5_25.5': 712, 'B5_28.0': 713, 'B5_3.0': 714, 'B5_3.25': 715, 'B5_3.5': 716, 'B5_30.25': 717, 'B5_30.5': 718, 'B5_32.5': 719, 'B5_33.0': 720, 'B5_37.25': 721, 'B5_4.0': 722, 'B5_4.25': 723, 'B5_4.5': 724, 'B5_4.75': 725, 'B5_4/3': 726, 'B5_42.0': 727, 'B5_48.0': 728, 'B5_49.0': 729, 'B5_5.0': 730, 'B5_5.25': 731, 'B5_5.5': 732, 'B5_5/3': 733, 'B5_54.5': 734, 'B5_6.0': 735, 'B5_6.25': 736, 'B5_6.5': 737, 'B5_6.75': 738, 'B5_63.0': 739, 'B5_7.0': 740, 'B5_7.5': 741, 'B5_7.75': 742, 'B5_7/3': 743, 'B5_8.0': 744, 'B5_8.5': 745, 'B5_8/3': 746, 'B5_9.0': 747, 'B5_9.25': 748, 'B5_9.5': 749, 'B5_98.75': 750, 'C#2_0.25': 751, 'C#2_0.5': 752, 'C#2_0.75': 753, 'C#2_1.0': 754, 'C#2_1/3': 755, 'C#2_85.5': 756, 'C#3_0.25': 757, 'C#3_0.5': 758, 'C#3_1.0': 759, 'C#3_1.5': 760, 'C#3_1/3': 761, 'C#3_2.0': 762, 'C#3_3.0': 763, 'C#3_56.0': 764, 'C#3_6.0': 765, 'C#3_8.0': 766, 'C#4_0.25': 767, 'C#4_0.5': 768, 'C#4_1.0': 769, 'C#4_1.25': 770, 'C#4_1.5': 771, 'C#4_1.75': 772, 'C#4_1/3': 773, 'C#4_125.0': 774, 'C#4_17.5': 775, 'C#4_2.0': 776, 'C#4_23.75': 777, 'C#4_26.25': 778, 'C#4_3.0': 779, 'C#4_4.0': 780, 'C#4_83.75': 781, 'C#5_0.0': 782, 'C#5_0.25': 783, 'C#5_0.5': 784, 'C#5_0.75': 785, 'C#5_1.0': 786, 'C#5_1.5': 787, 'C#5_1.75': 788, 'C#5_1/3': 789, 'C#5_10.25': 790, 'C#5_11.0': 791, 'C#5_11.25': 792, 'C#5_114.0': 793, 'C#5_118.25': 794, 'C#5_12.0': 795, 'C#5_12.5': 796, 'C#5_134/3': 797, 'C#5_14.25': 798, 'C#5_15.0': 799, 'C#5_15.5': 800, 'C#5_16.25': 801, 'C#5_17.0': 802, 'C#5_17.25': 803, 'C#5_18.25': 804, 'C#5_18.5': 805, 'C#5_2.0': 806, 'C#5_2.5': 807, 'C#5_2.75': 808, 'C#5_20.0': 809, 'C#5_20.5': 810, 'C#5_21.25': 811, 'C#5_226.75': 812, 'C#5_25.25': 813, 'C#5_25.75': 814, 'C#5_27.75': 815, 'C#5_28.0': 816, 'C#5_3.0': 817, 'C#5_3.5': 818, 'C#5_30.0': 819, 'C#5_30.25': 820, 'C#5_31.25': 821, 'C#5_32.0': 822, 'C#5_36.5': 823, 'C#5_38.0': 824, 'C#5_4.0': 825, 'C#5_4.5': 826, 'C#5_42.5': 827, 'C#5_43.0': 828, 'C#5_47.5': 829, 'C#5_5.0': 830, 'C#5_58.25': 831, 'C#5_6.0': 832, 'C#5_6.75': 833, 'C#5_61.5': 834, 'C#5_7.0': 835, 'C#5_7.5': 836, 'C#5_7.75': 837, 'C#5_8.0': 838, 'C#5_8.75': 839, 'C#5_9.75': 840, 'C#6_0.25': 841, 'C#6_0.5': 842, 'C#6_0.75': 843, 'C#6_1.0': 844, 'C#6_1.5': 845, 'C#6_105.5': 846, 'C#6_12.0': 847, 'C#6_14.0': 848, 'C#6_15.25': 849, 'C#6_169.0': 850, 'C#6_2.0': 851, 'C#6_24.75': 852, 'C#6_4.0': 853, 'C#6_6.0': 854, 'C#6_67.25': 855, 'C1_0.5': 856, 'C1_1.0': 857, 'C2_0.25': 858, 'C2_0.5': 859, 'C2_0.75': 860, 'C2_1.0': 861, 'C2_1.5': 862, 'C2_11.5': 863, 'C2_13.5': 864, 'C2_138.0': 865, 'C2_17.75': 866, 'C2_2.0': 867, 'C2_2.5': 868, 'C2_34.5': 869, 'C2_45.0': 870, 'C2_6.0': 871, 'C2_7.25': 872, 'C3_0.25': 873, 'C3_0.5': 874, 'C3_0.75': 875, 'C3_1.0': 876, 'C3_1.25': 877, 'C3_1.5': 878, 'C3_1.75': 879, 'C3_1/3': 880, 'C3_10.0': 881, 'C3_11.0': 882, 'C3_15.0': 883, 'C3_15.25': 884, 'C3_2.0': 885, 'C3_2.25': 886, 'C3_2.5': 887, 'C3_25.75': 888, 'C3_26.25': 889, 'C3_28.5': 890, 'C3_29.5': 891, 'C3_3.0': 892, 'C3_3.5': 893, 'C3_32.25': 894, 'C3_34.0': 895, 'C3_4.75': 896, 'C3_6.25': 897, 'C3_6.75': 898, 'C3_8.0': 899, 'C3_9.25': 900, 'C4_0.0': 901, 'C4_0.25': 902, 'C4_0.5': 903, 'C4_0.75': 904, 'C4_1.0': 905, 'C4_1.25': 906, 'C4_1.5': 907, 'C4_1.75': 908, 'C4_1/3': 909, 'C4_10.0': 910, 'C4_11.25': 911, 'C4_11.5': 912, 'C4_11/3': 913, 'C4_13/3': 914, 'C4_14.0': 915, 'C4_15.25': 916, 'C4_15.5': 917, 'C4_15.75': 918, 'C4_16.0': 919, 'C4_17/3': 920, 'C4_19.25': 921, 'C4_2.0': 922, 'C4_2.25': 923, 'C4_2.5': 924, 'C4_2.75': 925, 'C4_2/3': 926, 'C4_20.25': 927, 'C4_22.0': 928, 'C4_28.0': 929, 'C4_29.25': 930, 'C4_3.0': 931, 'C4_3.25': 932, 'C4_3.5': 933, 'C4_3.75': 934, 'C4_31.75': 935, 'C4_312.0': 936, 'C4_32.0': 937, 'C4_37.25': 938, 'C4_37/3': 939, 'C4_4.0': 940, 'C4_4.25': 941, 'C4_4.75': 942, 'C4_44.25': 943, 'C4_47.25': 944, 'C4_5.0': 945, 'C4_5.25': 946, 'C4_5.75': 947, 'C4_5/3': 948, 'C4_59/3': 949, 'C4_6.0': 950, 'C4_6.25': 951, 'C4_6.75': 952, 'C4_7.0': 953, 'C4_7.25': 954, 'C4_7.5': 955, 'C4_7/3': 956, 'C4_9.25': 957, 'C4_97.0': 958, 'C5_0.0': 959, 'C5_0.25': 960, 'C5_0.5': 961, 'C5_0.75': 962, 'C5_1.0': 963, 'C5_1.25': 964, 'C5_1.5': 965, 'C5_1.75': 966, 'C5_1/3': 967, 'C5_10.75': 968, 'C5_10/3': 969, 'C5_11.0': 970, 'C5_11.25': 971, 'C5_11/3': 972, 'C5_12.0': 973, 'C5_12.5': 974, 'C5_13.25': 975, 'C5_13/3': 976, 'C5_14.0': 977, 'C5_15.0': 978, 'C5_15.25': 979, 'C5_16.0': 980, 'C5_16.25': 981, 'C5_17.0': 982, 'C5_17.75': 983, 'C5_18.75': 984, 'C5_2.0': 985, 'C5_2.25': 986, 'C5_2.5': 987, 'C5_2.75': 988, 'C5_2/3': 989, 'C5_20.0': 990, 'C5_21.0': 991, 'C5_21.25': 992, 'C5_23.0': 993, 'C5_23/3': 994, 'C5_24.75': 995, 'C5_25.25': 996, 'C5_25.75': 997, 'C5_26/3': 998, 'C5_28/3': 999, 'C5_29/3': 1000, 'C5_3.0': 1001, 'C5_3.25': 1002, 'C5_3.5': 1003, 'C5_3.75': 1004, 'C5_30.0': 1005, 'C5_31/3': 1006, 'C5_4.0': 1007, 'C5_4.25': 1008, 'C5_4.5': 1009, 'C5_4.75': 1010, 'C5_4/3': 1011, 'C5_49.0': 1012, 'C5_49.25': 1013, 'C5_49/3': 1014, 'C5_5.0': 1015, 'C5_5.25': 1016, 'C5_5.5': 1017, 'C5_5.75': 1018, 'C5_5/3': 1019, 'C5_6.0': 1020, 'C5_6.25': 1021, 'C5_6.5': 1022, 'C5_6.75': 1023, 'C5_65/3': 1024, 'C5_7.0': 1025, 'C5_7.25': 1026, 'C5_7.5': 1027, 'C5_7.75': 1028, 'C5_8.0': 1029, 'C5_8.25': 1030, 'C5_8/3': 1031, 'C5_9.0': 1032, 'C5_9.25': 1033, 'C5_9.5': 1034, 'C5_9.75': 1035, 'C6_0.0': 1036, 'C6_0.25': 1037, 'C6_0.5': 1038, 'C6_0.75': 1039, 'C6_1.0': 1040, 'C6_1.25': 1041, 'C6_1.5': 1042, 'C6_1.75': 1043, 'C6_1/3': 1044, 'C6_107.75': 1045, 'C6_11.5': 1046, 'C6_113/3': 1047, 'C6_12.5': 1048, 'C6_13.0': 1049, 'C6_13.5': 1050, 'C6_13/3': 1051, 'C6_15.25': 1052, 'C6_15.5': 1053, 'C6_16.0': 1054, 'C6_16.75': 1055, 'C6_16/3': 1056, 'C6_17.25': 1057, 'C6_19.0': 1058, 'C6_2.0': 1059, 'C6_2.25': 1060, 'C6_2.5': 1061, 'C6_2.75': 1062, 'C6_2/3': 1063, 'C6_20.75': 1064, 'C6_24.5': 1065, 'C6_28.75': 1066, 'C6_3.0': 1067, 'C6_3.25': 1068, 'C6_3.5': 1069, 'C6_3.75': 1070, 'C6_32.0': 1071, 'C6_34.25': 1072, 'C6_35.25': 1073, 'C6_39.5': 1074, 'C6_4.0': 1075, 'C6_4.25': 1076, 'C6_4.5': 1077, 'C6_4.75': 1078, 'C6_4/3': 1079, 'C6_41/3': 1080, 'C6_47/3': 1081, 'C6_5.0': 1082, 'C6_5.25': 1083, 'C6_5.5': 1084, 'C6_5.75': 1085, 'C6_5/3': 1086, 'C6_52.5': 1087, 'C6_55.0': 1088, 'C6_6.0': 1089, 'C6_6.25': 1090, 'C6_63.25': 1091, 'C6_64/3': 1092, 'C6_7.25': 1093, 'C6_7.5': 1094, 'C6_7/3': 1095, 'C6_74/3': 1096, 'C6_8.25': 1097, 'C6_8.5': 1098, 'C6_8.75': 1099, 'C6_8/3': 1100, 'C6_9.5': 1101, 'C6_92/3': 1102, 'D1_3.0': 1103, 'D1_88.0': 1104, 'D2_0.25': 1105, 'D2_0.5': 1106, 'D2_0.75': 1107, 'D2_1.0': 1108, 'D2_1.25': 1109, 'D2_1.5': 1110, 'D2_1/3': 1111, 'D2_19.25': 1112, 'D2_2.0': 1113, 'D2_2.25': 1114, 'D2_2.5': 1115, 'D2_3.0': 1116, 'D2_35.0': 1117, 'D2_4.0': 1118, 'D3_0.0': 1119, 'D3_0.25': 1120, 'D3_0.5': 1121, 'D3_0.75': 1122, 'D3_1.0': 1123, 'D3_1.25': 1124, 'D3_1.5': 1125, 'D3_1.75': 1126, 'D3_1/3': 1127, 'D3_11.0': 1128, 'D3_13.0': 1129, 'D3_13.25': 1130, 'D3_16.0': 1131, 'D3_16.5': 1132, 'D3_16.75': 1133, 'D3_17/3': 1134, 'D3_18.75': 1135, 'D3_19.5': 1136, 'D3_19.75': 1137, 'D3_2.0': 1138, 'D3_2.25': 1139, 'D3_2.5': 1140, 'D3_2/3': 1141, 'D3_27.25': 1142, 'D3_28/3': 1143, 'D3_3.0': 1144, 'D3_3.5': 1145, 'D3_31.25': 1146, 'D3_4.0': 1147, 'D3_43.0': 1148, 'D3_47.75': 1149, 'D3_5.0': 1150, 'D3_5.25': 1151, 'D3_5/3': 1152, 'D3_95.0': 1153, 'D4_0.0': 1154, 'D4_0.25': 1155, 'D4_0.5': 1156, 'D4_0.75': 1157, 'D4_1.0': 1158, 'D4_1.25': 1159, 'D4_1.5': 1160, 'D4_1.75': 1161, 'D4_1/3': 1162, 'D4_10.0': 1163, 'D4_10.25': 1164, 'D4_104.25': 1165, 'D4_11.5': 1166, 'D4_11.75': 1167, 'D4_11/3': 1168, 'D4_12.0': 1169, 'D4_12.75': 1170, 'D4_13.0': 1171, 'D4_13.5': 1172, 'D4_13/3': 1173, 'D4_139.5': 1174, 'D4_14.25': 1175, 'D4_16.0': 1176, 'D4_16/3': 1177, 'D4_17.0': 1178, 'D4_17.75': 1179, 'D4_19/3': 1180, 'D4_2.0': 1181, 'D4_2.25': 1182, 'D4_2.5': 1183, 'D4_2.75': 1184, 'D4_2/3': 1185, 'D4_20.5': 1186, 'D4_20.75': 1187, 'D4_23.5': 1188, 'D4_24.5': 1189, 'D4_25.25': 1190, 'D4_27.75': 1191, 'D4_29.75': 1192, 'D4_3.0': 1193, 'D4_3.25': 1194, 'D4_3.5': 1195, 'D4_3.75': 1196, 'D4_30.25': 1197, 'D4_34/3': 1198, 'D4_35.75': 1199, 'D4_36.0': 1200, 'D4_37.25': 1201, 'D4_37.5': 1202, 'D4_38/3': 1203, 'D4_4.0': 1204, 'D4_4.25': 1205, 'D4_4.5': 1206, 'D4_4.75': 1207, 'D4_4/3': 1208, 'D4_5.0': 1209, 'D4_5.25': 1210, 'D4_5.5': 1211, 'D4_5.75': 1212, 'D4_52.25': 1213, 'D4_6.0': 1214, 'D4_6.5': 1215, 'D4_6.75': 1216, 'D4_62.75': 1217, 'D4_64.5': 1218, 'D4_7.0': 1219, 'D4_7.25': 1220, 'D4_7.5': 1221, 'D4_7.75': 1222, 'D4_7/3': 1223, 'D4_8.0': 1224, 'D4_9.0': 1225, 'D4_9.25': 1226, 'D4_9.5': 1227, 'D5_0.0': 1228, 'D5_0.25': 1229, 'D5_0.5': 1230, 'D5_0.75': 1231, 'D5_1.0': 1232, 'D5_1.25': 1233, 'D5_1.5': 1234, 'D5_1.75': 1235, 'D5_1/3': 1236, 'D5_10.0': 1237, 'D5_10.25': 1238, 'D5_10.75': 1239, 'D5_10/3': 1240, 'D5_11.0': 1241, 'D5_11.25': 1242, 'D5_11.75': 1243, 'D5_11/3': 1244, 'D5_12.0': 1245, 'D5_12.25': 1246, 'D5_12.5': 1247, 'D5_12.75': 1248, 'D5_13.5': 1249, 'D5_13.75': 1250, 'D5_14.5': 1251, 'D5_15.75': 1252, 'D5_16.75': 1253, 'D5_16/3': 1254, 'D5_17.25': 1255, 'D5_18.0': 1256, 'D5_19.5': 1257, 'D5_2.0': 1258, 'D5_2.25': 1259, 'D5_2.5': 1260, 'D5_2.75': 1261, 'D5_2/3': 1262, 'D5_20.75': 1263, 'D5_20/3': 1264, 'D5_21.25': 1265, 'D5_22/3': 1266, 'D5_23.75': 1267, 'D5_26/3': 1268, 'D5_3.0': 1269, 'D5_3.25': 1270, 'D5_3.5': 1271, 'D5_3.75': 1272, 'D5_4.0': 1273, 'D5_4.25': 1274, 'D5_4.5': 1275, 'D5_4.75': 1276, 'D5_4/3': 1277, 'D5_49.25': 1278, 'D5_5.0': 1279, 'D5_5.25': 1280, 'D5_5.5': 1281, 'D5_5.75': 1282, 'D5_5/3': 1283, 'D5_6.0': 1284, 'D5_6.25': 1285, 'D5_6.5': 1286, 'D5_6.75': 1287, 'D5_61.0': 1288, 'D5_7.0': 1289, 'D5_7.25': 1290, 'D5_7.5': 1291, 'D5_7.75': 1292, 'D5_8.0': 1293, 'D5_8.25': 1294, 'D5_8.5': 1295, 'D5_8.75': 1296, 'D5_8/3': 1297, 'D5_9.0': 1298, 'D5_9.25': 1299, 'D5_9.5': 1300, 'D6_0.0': 1301, 'D6_0.25': 1302, 'D6_0.5': 1303, 'D6_0.75': 1304, 'D6_1.0': 1305, 'D6_1.25': 1306, 'D6_1.5': 1307, 'D6_1.75': 1308, 'D6_1/3': 1309, 'D6_10.5': 1310, 'D6_10/3': 1311, 'D6_11.75': 1312, 'D6_12.5': 1313, 'D6_13.75': 1314, 'D6_14.0': 1315, 'D6_16/3': 1316, 'D6_2.0': 1317, 'D6_2.5': 1318, 'D6_2.75': 1319, 'D6_2/3': 1320, 'D6_20.0': 1321, 'D6_21.0': 1322, 'D6_21.25': 1323, 'D6_22.0': 1324, 'D6_22.75': 1325, 'D6_24.75': 1326, 'D6_25.5': 1327, 'D6_3.0': 1328, 'D6_3.5': 1329, 'D6_30.75': 1330, 'D6_32.0': 1331, 'D6_32.25': 1332, 'D6_33.75': 1333, 'D6_34.5': 1334, 'D6_35.5': 1335, 'D6_38.75': 1336, 'D6_4.0': 1337, 'D6_4.5': 1338, 'D6_41.5': 1339, 'D6_47.25': 1340, 'D6_5.0': 1341, 'D6_5.25': 1342, 'D6_5.5': 1343, 'D6_5.75': 1344, 'D6_6.0': 1345, 'D6_6.25': 1346, 'D6_61.25': 1347, 'D6_7.0': 1348, 'D6_7.75': 1349, 'D6_7/3': 1350, 'D6_8.0': 1351, 'D6_8.25': 1352, 'D6_8.75': 1353, 'D6_9.0': 1354, 'D6_9.5': 1355, 'D6_93.5': 1356, 'E-1_0.5': 1357, 'E-1_3.0': 1358, 'E-2_0.25': 1359, 'E-2_0.5': 1360, 'E-2_1.0': 1361, 'E-2_3.0': 1362, 'E-2_6.0': 1363, 'E-3_0.25': 1364, 'E-3_0.5': 1365, 'E-3_0.75': 1366, 'E-3_1.0': 1367, 'E-3_1.5': 1368, 'E-3_1/3': 1369, 'E-3_19.25': 1370, 'E-3_3.0': 1371, 'E-3_4.0': 1372, 'E-3_44.0': 1373, 'E-3_60.0': 1374, 'E-3_7.25': 1375, 'E-4_0.25': 1376, 'E-4_0.5': 1377, 'E-4_0.75': 1378, 'E-4_1.0': 1379, 'E-4_1.25': 1380, 'E-4_1.5': 1381, 'E-4_1/3': 1382, 'E-4_2.0': 1383, 'E-4_21.25': 1384, 'E-4_3.0': 1385, 'E-4_61.5': 1386, 'E-4_79/3': 1387, 'E-4_89.25': 1388, 'E-4_9.0': 1389, 'E-5_0.0': 1390, 'E-5_0.25': 1391, 'E-5_0.5': 1392, 'E-5_0.75': 1393, 'E-5_1.0': 1394, 'E-5_1.25': 1395, 'E-5_1.5': 1396, 'E-5_1/3': 1397, 'E-5_10.0': 1398, 'E-5_11.0': 1399, 'E-5_11.5': 1400, 'E-5_110.25': 1401, 'E-5_12.0': 1402, 'E-5_12.5': 1403, 'E-5_13.5': 1404, 'E-5_154.0': 1405, 'E-5_19.5': 1406, 'E-5_2.0': 1407, 'E-5_2.5': 1408, 'E-5_21.0': 1409, 'E-5_23.0': 1410, 'E-5_24.0': 1411, 'E-5_24.75': 1412, 'E-5_26.0': 1413, 'E-5_27.5': 1414, 'E-5_28.75': 1415, 'E-5_3.0': 1416, 'E-5_3.5': 1417, 'E-5_3.75': 1418, 'E-5_306.75': 1419, 'E-5_4.0': 1420, 'E-5_4.25': 1421, 'E-5_4.5': 1422, 'E-5_42.0': 1423, 'E-5_46.75': 1424, 'E-5_48.25': 1425, 'E-5_56.0': 1426, 'E-5_7.5': 1427, 'E-5_7.75': 1428, 'E-5_8.25': 1429, 'E-5_81.75': 1430, 'E-5_82.5': 1431, 'E-5_86.75': 1432, 'E-5_88.5': 1433, 'E-5_97.0': 1434, 'E-5_99.75': 1435, 'E-6_0.0': 1436, 'E-6_0.25': 1437, 'E-6_0.5': 1438, 'E-6_0.75': 1439, 'E-6_1.0': 1440, 'E-6_1.25': 1441, 'E-6_1.5': 1442, 'E-6_1/3': 1443, 'E-6_2.0': 1444, 'E-6_2.25': 1445, 'E-6_37.25': 1446, 'E-6_46.5': 1447, 'E-6_68.0': 1448, 'E-6_680/3': 1449, 'E-6_86/3': 1450, 'E1_0.25': 1451, 'E1_0.5': 1452, 'E1_1.0': 1453, 'E1_1.5': 1454, 'E1_3.0': 1455, 'E2_0.25': 1456, 'E2_0.5': 1457, 'E2_0.75': 1458, 'E2_1.0': 1459, 'E2_1.5': 1460, 'E2_1/3': 1461, 'E2_15.25': 1462, 'E2_16.25': 1463, 'E2_17.25': 1464, 'E2_2.0': 1465, 'E2_3.0': 1466, 'E2_35/3': 1467, 'E2_5.0': 1468, 'E2_6.0': 1469, 'E2_6.25': 1470, 'E3_0.25': 1471, 'E3_0.5': 1472, 'E3_0.75': 1473, 'E3_1.0': 1474, 'E3_1.25': 1475, 'E3_1.5': 1476, 'E3_1/3': 1477, 'E3_10.75': 1478, 'E3_12.5': 1479, 'E3_16.0': 1480, 'E3_182/3': 1481, 'E3_2.0': 1482, 'E3_2.25': 1483, 'E3_2.5': 1484, 'E3_2/3': 1485, 'E3_20.5': 1486, 'E3_22.25': 1487, 'E3_29.0': 1488, 'E3_3.0': 1489, 'E3_3.25': 1490, 'E3_31.25': 1491, 'E3_37.75': 1492, 'E3_4.0': 1493, 'E3_4.25': 1494, 'E3_44.0': 1495, 'E3_44/3': 1496, 'E3_5.5': 1497, 'E3_50.75': 1498, 'E3_54.0': 1499, 'E3_6.0': 1500, 'E3_7.5': 1501, 'E3_7.75': 1502, 'E3_8.0': 1503, 'E3_9.25': 1504, 'E3_94/3': 1505, 'E4_0.0': 1506, 'E4_0.25': 1507, 'E4_0.5': 1508, 'E4_0.75': 1509, 'E4_1.0': 1510, 'E4_1.25': 1511, 'E4_1.5': 1512, 'E4_1.75': 1513, 'E4_1/3': 1514, 'E4_10.0': 1515, 'E4_10.25': 1516, 'E4_10.75': 1517, 'E4_10/3': 1518, 'E4_11.5': 1519, 'E4_11.75': 1520, 'E4_12.0': 1521, 'E4_12.5': 1522, 'E4_120.0': 1523, 'E4_124.0': 1524, 'E4_124/3': 1525, 'E4_129.5': 1526, 'E4_13.0': 1527, 'E4_14/3': 1528, 'E4_16.0': 1529, 'E4_16.5': 1530, 'E4_17.0': 1531, 'E4_17.5': 1532, 'E4_18.0': 1533, 'E4_18.5': 1534, 'E4_19.25': 1535, 'E4_2.0': 1536, 'E4_2.25': 1537, 'E4_2.5': 1538, 'E4_2.75': 1539, 'E4_2/3': 1540, 'E4_20.25': 1541, 'E4_20/3': 1542, 'E4_22/3': 1543, 'E4_23.25': 1544, 'E4_25/3': 1545, 'E4_26/3': 1546, 'E4_27.25': 1547, 'E4_28.25': 1548, 'E4_29.25': 1549, 'E4_3.0': 1550, 'E4_3.25': 1551, 'E4_3.5': 1552, 'E4_33.5': 1553, 'E4_34.25': 1554, 'E4_34/3': 1555, 'E4_35.5': 1556, 'E4_36.0': 1557, 'E4_4.0': 1558, 'E4_4.25': 1559, 'E4_4.75': 1560, 'E4_4/3': 1561, 'E4_41/3': 1562, 'E4_46.5': 1563, 'E4_5.0': 1564, 'E4_5.25': 1565, 'E4_5.5': 1566, 'E4_5.75': 1567, 'E4_56.0': 1568, 'E4_6.0': 1569, 'E4_6.25': 1570, 'E4_6.5': 1571, 'E4_6.75': 1572, 'E4_7.0': 1573, 'E4_7.25': 1574, 'E4_7.75': 1575, 'E4_8.0': 1576, 'E4_8.25': 1577, 'E4_9.0': 1578, 'E4_9.25': 1579, 'E4_9.5': 1580, 'E4_9.75': 1581, 'E4_90.0': 1582, 'E4_95.75': 1583, 'E5_0.0': 1584, 'E5_0.25': 1585, 'E5_0.5': 1586, 'E5_0.75': 1587, 'E5_1.0': 1588, 'E5_1.25': 1589, 'E5_1.5': 1590, 'E5_1.75': 1591, 'E5_1/3': 1592, 'E5_10.0': 1593, 'E5_10.5': 1594, 'E5_10/3': 1595, 'E5_11.0': 1596, 'E5_11.5': 1597, 'E5_11.75': 1598, 'E5_11/3': 1599, 'E5_12.0': 1600, 'E5_13.0': 1601, 'E5_13/3': 1602, 'E5_14.25': 1603, 'E5_14.5': 1604, 'E5_14.75': 1605, 'E5_15.75': 1606, 'E5_16.25': 1607, 'E5_17.75': 1608, 'E5_18.5': 1609, 'E5_18.75': 1610, 'E5_19/3': 1611, 'E5_2.0': 1612, 'E5_2.25': 1613, 'E5_2.5': 1614, 'E5_2.75': 1615, 'E5_2/3': 1616, 'E5_21.0': 1617, 'E5_23.5': 1618, 'E5_24.75': 1619, 'E5_26/3': 1620, 'E5_3.0': 1621, 'E5_3.25': 1622, 'E5_3.5': 1623, 'E5_3.75': 1624, 'E5_31/3': 1625, 'E5_35/3': 1626, 'E5_36.25': 1627, 'E5_39.0': 1628, 'E5_4.0': 1629, 'E5_4.25': 1630, 'E5_4.5': 1631, 'E5_4.75': 1632, 'E5_4/3': 1633, 'E5_5.0': 1634, 'E5_5.25': 1635, 'E5_5.5': 1636, 'E5_5.75': 1637, 'E5_5/3': 1638, 'E5_56/3': 1639, 'E5_6.0': 1640, 'E5_6.25': 1641, 'E5_6.5': 1642, 'E5_6.75': 1643, 'E5_62/3': 1644, 'E5_7.0': 1645, 'E5_7.25': 1646, 'E5_7.75': 1647, 'E5_7/3': 1648, 'E5_8.0': 1649, 'E5_8.25': 1650, 'E5_8.5': 1651, 'E5_8.75': 1652, 'E5_8/3': 1653, 'E5_9.0': 1654, 'E5_9.25': 1655, 'E6_0.0': 1656, 'E6_0.25': 1657, 'E6_0.5': 1658, 'E6_0.75': 1659, 'E6_1.0': 1660, 'E6_1.25': 1661, 'E6_1.5': 1662, 'E6_1/3': 1663, 'E6_10.25': 1664, 'E6_10.75': 1665, 'E6_13.0': 1666, 'E6_13.75': 1667, 'E6_14.0': 1668, 'E6_15.5': 1669, 'E6_15.75': 1670, 'E6_16.25': 1671, 'E6_17.5': 1672, 'E6_19.0': 1673, 'E6_2.0': 1674, 'E6_2.25': 1675, 'E6_2.5': 1676, 'E6_21.25': 1677, 'E6_22.75': 1678, 'E6_27.25': 1679, 'E6_27.75': 1680, 'E6_3.0': 1681, 'E6_3.5': 1682, 'E6_30.25': 1683, 'E6_31.5': 1684, 'E6_31/3': 1685, 'E6_36.75': 1686, 'E6_4.0': 1687, 'E6_4.75': 1688, 'E6_40.0': 1689, 'E6_50.5': 1690, 'E6_52.0': 1691, 'E6_53.75': 1692, 'E6_79/3': 1693, 'E6_8.0': 1694, 'E6_9.5': 1695, 'E6_9.75': 1696, 'F#1_0.25': 1697, 'F#1_0.5': 1698, 'F#1_1.0': 1699, 'F#1_71.25': 1700, 'F#2_0.0': 1701, 'F#2_0.25': 1702, 'F#2_0.5': 1703, 'F#2_0.75': 1704, 'F#2_1.0': 1705, 'F#2_1/3': 1706, 'F#2_2.25': 1707, 'F#2_64.0': 1708, 'F#2_65/3': 1709, 'F#3_0.25': 1710, 'F#3_0.5': 1711, 'F#3_0.75': 1712, 'F#3_1.0': 1713, 'F#3_1.5': 1714, 'F#3_1/3': 1715, 'F#3_119.0': 1716, 'F#3_18.75': 1717, 'F#3_2.0': 1718, 'F#3_24.5': 1719, 'F#3_257/3': 1720, 'F#3_26.25': 1721, 'F#3_29.5': 1722, 'F#3_3.0': 1723, 'F#3_4.5': 1724, 'F#3_42.5': 1725, 'F#3_5.0': 1726, 'F#3_6.0': 1727, 'F#3_68.25': 1728, 'F#3_8.0': 1729, 'F#4_0.0': 1730, 'F#4_0.25': 1731, 'F#4_0.5': 1732, 'F#4_0.75': 1733, 'F#4_1.0': 1734, 'F#4_1.25': 1735, 'F#4_1.5': 1736, 'F#4_1/3': 1737, 'F#4_10.0': 1738, 'F#4_10.5': 1739, 'F#4_10/3': 1740, 'F#4_11.5': 1741, 'F#4_11.75': 1742, 'F#4_114.75': 1743, 'F#4_12.0': 1744, 'F#4_13.0': 1745, 'F#4_14.0': 1746, 'F#4_14.25': 1747, 'F#4_14.75': 1748, 'F#4_15.0': 1749, 'F#4_15.75': 1750, 'F#4_16.25': 1751, 'F#4_16/3': 1752, 'F#4_2.0': 1753, 'F#4_2/3': 1754, 'F#4_20.75': 1755, 'F#4_201.0': 1756, 'F#4_21.25': 1757, 'F#4_22.75': 1758, 'F#4_23/3': 1759, 'F#4_25.0': 1760, 'F#4_252.0': 1761, 'F#4_28.25': 1762, 'F#4_29.25': 1763, 'F#4_29/3': 1764, 'F#4_3.0': 1765, 'F#4_3.25': 1766, 'F#4_3.5': 1767, 'F#4_3.75': 1768, 'F#4_30.0': 1769, 'F#4_31.5': 1770, 'F#4_32/3': 1771, 'F#4_33.5': 1772, 'F#4_35.75': 1773, 'F#4_38.0': 1774, 'F#4_4.0': 1775, 'F#4_4.25': 1776, 'F#4_4.5': 1777, 'F#4_43.25': 1778, 'F#4_43/3': 1779, 'F#4_48.0': 1780, 'F#4_5.5': 1781, 'F#4_5.75': 1782, 'F#4_54.5': 1783, 'F#4_586/3': 1784, 'F#4_59.5': 1785, 'F#4_6.25': 1786, 'F#4_6.5': 1787, 'F#4_7.25': 1788, 'F#4_8.0': 1789, 'F#4_8.75': 1790, 'F#4_8/3': 1791, 'F#4_92/3': 1792, 'F#5_0.25': 1793, 'F#5_0.5': 1794, 'F#5_0.75': 1795, 'F#5_1.0': 1796, 'F#5_1.25': 1797, 'F#5_1.5': 1798, 'F#5_1.75': 1799, 'F#5_1/3': 1800, 'F#5_10/3': 1801, 'F#5_11.0': 1802, 'F#5_11.25': 1803, 'F#5_11/3': 1804, 'F#5_12.5': 1805, 'F#5_13.5': 1806, 'F#5_13/3': 1807, 'F#5_133.0': 1808, 'F#5_14.25': 1809, 'F#5_15.0': 1810, 'F#5_16.25': 1811, 'F#5_166/3': 1812, 'F#5_17.5': 1813, 'F#5_18.5': 1814, 'F#5_19.0': 1815, 'F#5_19/3': 1816, 'F#5_2.0': 1817, 'F#5_2.25': 1818, 'F#5_2.5': 1819, 'F#5_2.75': 1820, 'F#5_21.5': 1821, 'F#5_23.75': 1822, 'F#5_24.0': 1823, 'F#5_25.25': 1824, 'F#5_26.5': 1825, 'F#5_27.5': 1826, 'F#5_28.0': 1827, 'F#5_3.0': 1828, 'F#5_3.25': 1829, 'F#5_3.5': 1830, 'F#5_3.75': 1831, 'F#5_30.25': 1832, 'F#5_31.5': 1833, 'F#5_32/3': 1834, 'F#5_34.75': 1835, 'F#5_37.75': 1836, 'F#5_39.75': 1837, 'F#5_4.0': 1838, 'F#5_4.25': 1839, 'F#5_4.5': 1840, 'F#5_4.75': 1841, 'F#5_41.0': 1842, 'F#5_41.5': 1843, 'F#5_45.75': 1844, 'F#5_5.0': 1845, 'F#5_5.25': 1846, 'F#5_5.5': 1847, 'F#5_5.75': 1848, 'F#5_5/3': 1849, 'F#5_53.5': 1850, 'F#5_53.75': 1851, 'F#5_55.75': 1852, 'F#5_6.0': 1853, 'F#5_6.25': 1854, 'F#5_6.5': 1855, 'F#5_61.0': 1856, 'F#5_63.25': 1857, 'F#5_69.75': 1858, 'F#5_7.0': 1859, 'F#5_7.25': 1860, 'F#5_7.5': 1861, 'F#5_74/3': 1862, 'F#5_8.0': 1863, 'F#5_8.25': 1864, 'F#5_8/3': 1865, 'F#5_9.0': 1866, 'F#5_9.75': 1867, 'F#6_0.25': 1868, 'F#6_0.5': 1869, 'F#6_1.0': 1870, 'F#6_15.25': 1871, 'F#6_174.5': 1872, 'F#6_63.0': 1873, 'F1_0.25': 1874, 'F1_0.5': 1875, 'F1_2.0': 1876, 'F1_3.0': 1877, 'F2_0.25': 1878, 'F2_0.5': 1879, 'F2_1.0': 1880, 'F2_1.5': 1881, 'F2_1/3': 1882, 'F2_12.5': 1883, 'F2_2.0': 1884, 'F2_21.5': 1885, 'F2_3.0': 1886, 'F2_4.0': 1887, 'F2_6.0': 1888, 'F2_8.0': 1889, 'F3_0.0': 1890, 'F3_0.25': 1891, 'F3_0.5': 1892, 'F3_0.75': 1893, 'F3_1.0': 1894, 'F3_1.5': 1895, 'F3_1/3': 1896, 'F3_13.25': 1897, 'F3_13.5': 1898, 'F3_14.0': 1899, 'F3_14.25': 1900, 'F3_2.0': 1901, 'F3_2.25': 1902, 'F3_2/3': 1903, 'F3_23/3': 1904, 'F3_3.0': 1905, 'F3_3.25': 1906, 'F3_3.5': 1907, 'F3_3.75': 1908, 'F3_31.25': 1909, 'F3_32.25': 1910, 'F3_33.0': 1911, 'F3_4.0': 1912, 'F3_57.25': 1913, 'F3_6.0': 1914, 'F3_8.0': 1915, 'F3_8.25': 1916, 'F3_9.25': 1917, 'F3_90.75': 1918, 'F4_0.0': 1919, 'F4_0.25': 1920, 'F4_0.5': 1921, 'F4_0.75': 1922, 'F4_1.0': 1923, 'F4_1.25': 1924, 'F4_1.5': 1925, 'F4_1.75': 1926, 'F4_1/3': 1927, 'F4_10.25': 1928, 'F4_10/3': 1929, 'F4_11.75': 1930, 'F4_12.75': 1931, 'F4_120.0': 1932, 'F4_14.5': 1933, 'F4_142/3': 1934, 'F4_15.0': 1935, 'F4_16.0': 1936, 'F4_16/3': 1937, 'F4_17.5': 1938, 'F4_2.0': 1939, 'F4_2.25': 1940, 'F4_2.5': 1941, 'F4_2.75': 1942, 'F4_2/3': 1943, 'F4_22.0': 1944, 'F4_22.25': 1945, 'F4_24.0': 1946, 'F4_27.0': 1947, 'F4_27.75': 1948, 'F4_3.0': 1949, 'F4_3.25': 1950, 'F4_3.5': 1951, 'F4_3.75': 1952, 'F4_30.5': 1953, 'F4_31.25': 1954, 'F4_34/3': 1955, 'F4_36.25': 1956, 'F4_362/3': 1957, 'F4_38/3': 1958, 'F4_4.0': 1959, 'F4_4.25': 1960, 'F4_4.75': 1961, 'F4_4/3': 1962, 'F4_41.0': 1963, 'F4_42.25': 1964, 'F4_5.0': 1965, 'F4_5.25': 1966, 'F4_5.5': 1967, 'F4_5.75': 1968, 'F4_52.0': 1969, 'F4_6.0': 1970, 'F4_6.25': 1971, 'F4_6.5': 1972, 'F4_61.5': 1973, 'F4_7.0': 1974, 'F4_7.25': 1975, 'F4_7.5': 1976, 'F4_7.75': 1977, 'F4_7/3': 1978, 'F4_8.0': 1979, 'F4_8.25': 1980, 'F4_9.0': 1981, 'F4_9.5': 1982, 'F4_9.75': 1983, 'F5_0.0': 1984, 'F5_0.25': 1985, 'F5_0.5': 1986, 'F5_0.75': 1987, 'F5_1.0': 1988, 'F5_1.25': 1989, 'F5_1.5': 1990, 'F5_1.75': 1991, 'F5_1/3': 1992, 'F5_10.0': 1993, 'F5_10.5': 1994, 'F5_100.75': 1995, 'F5_11.75': 1996, 'F5_12.0': 1997, 'F5_12.25': 1998, 'F5_12.75': 1999, 'F5_13.0': 2000, 'F5_13.25': 2001, 'F5_13/3': 2002, 'F5_14.0': 2003, 'F5_14.25': 2004, 'F5_14/3': 2005, 'F5_145/3': 2006, 'F5_16.0': 2007, 'F5_17/3': 2008, 'F5_2.0': 2009, 'F5_2.25': 2010, 'F5_2.5': 2011, 'F5_2.75': 2012, 'F5_2/3': 2013, 'F5_20.0': 2014, 'F5_26.25': 2015, 'F5_3.0': 2016, 'F5_3.25': 2017, 'F5_3.5': 2018, 'F5_3.75': 2019, 'F5_31/3': 2020, 'F5_34.0': 2021, 'F5_35.0': 2022, 'F5_4.0': 2023, 'F5_4.25': 2024, 'F5_4.5': 2025, 'F5_4.75': 2026, 'F5_4/3': 2027, 'F5_41.0': 2028, 'F5_46.75': 2029, 'F5_5.0': 2030, 'F5_5.25': 2031, 'F5_5.5': 2032, 'F5_5.75': 2033, 'F5_5/3': 2034, 'F5_50.5': 2035, 'F5_51.25': 2036, 'F5_55/3': 2037, 'F5_6.25': 2038, 'F5_6.5': 2039, 'F5_6.75': 2040, 'F5_7.0': 2041, 'F5_7.5': 2042, 'F5_7.75': 2043, 'F5_7/3': 2044, 'F5_8.0': 2045, 'F5_8.25': 2046, 'F5_8.5': 2047, 'F5_8.75': 2048, 'F5_8/3': 2049, 'F5_84.5': 2050, 'F5_9.0': 2051, 'F5_9.25': 2052, 'F5_9.5': 2053, 'F5_9.75': 2054, 'F6_0.25': 2055, 'F6_0.5': 2056, 'F6_0.75': 2057, 'F6_1.0': 2058, 'F6_1.25': 2059, 'F6_1.5': 2060, 'F6_10.0': 2061, 'F6_10.5': 2062, 'F6_11.5': 2063, 'F6_13.0': 2064, 'F6_14.0': 2065, 'F6_14.75': 2066, 'F6_2.0': 2067, 'F6_2.25': 2068, 'F6_2.75': 2069, 'F6_3.0': 2070, 'F6_3.5': 2071, 'F6_32.25': 2072, 'F6_33.75': 2073, 'F6_36.25': 2074, 'F6_39.0': 2075, 'F6_4/3': 2076, 'F6_40.25': 2077, 'F6_42.0': 2078, 'F6_48.75': 2079, 'F6_5/3': 2080, 'F6_6.5': 2081, 'G#1_0.25': 2082, 'G#1_0.5': 2083, 'G#1_1.0': 2084, 'G#1_5.0': 2085, 'G#2_0.0': 2086, 'G#2_0.25': 2087, 'G#2_0.5': 2088, 'G#2_0.75': 2089, 'G#2_1.0': 2090, 'G#2_1/3': 2091, 'G#2_17.5': 2092, 'G#2_4.0': 2093, 'G#3_0.25': 2094, 'G#3_0.5': 2095, 'G#3_0.75': 2096, 'G#3_1.0': 2097, 'G#3_1.25': 2098, 'G#3_1.5': 2099, 'G#3_1/3': 2100, 'G#3_2.25': 2101, 'G#3_3.0': 2102, 'G#3_4.0': 2103, 'G#3_43.25': 2104, 'G#3_7.25': 2105, 'G#4_0.0': 2106, 'G#4_0.25': 2107, 'G#4_0.5': 2108, 'G#4_1.0': 2109, 'G#4_1.25': 2110, 'G#4_1.5': 2111, 'G#4_1.75': 2112, 'G#4_1/3': 2113, 'G#4_11.25': 2114, 'G#4_11.5': 2115, 'G#4_12.0': 2116, 'G#4_12.25': 2117, 'G#4_155.75': 2118, 'G#4_17/3': 2119, 'G#4_18.5': 2120, 'G#4_18.75': 2121, 'G#4_19.0': 2122, 'G#4_2.0': 2123, 'G#4_2.75': 2124, 'G#4_24.25': 2125, 'G#4_247.0': 2126, 'G#4_28.0': 2127, 'G#4_28.5': 2128, 'G#4_3.0': 2129, 'G#4_3.5': 2130, 'G#4_3.75': 2131, 'G#4_38.25': 2132, 'G#4_38.5': 2133, 'G#4_4.0': 2134, 'G#4_41.75': 2135, 'G#4_52.0': 2136, 'G#4_56.0': 2137, 'G#4_6.0': 2138, 'G#4_60.0': 2139, 'G#4_61.75': 2140, 'G#4_7.0': 2141, 'G#4_8.0': 2142, 'G#4_85/3': 2143, 'G#4_9.75': 2144, 'G#5_0.0': 2145, 'G#5_0.25': 2146, 'G#5_0.5': 2147, 'G#5_0.75': 2148, 'G#5_1.0': 2149, 'G#5_1.25': 2150, 'G#5_1.5': 2151, 'G#5_1/3': 2152, 'G#5_10.0': 2153, 'G#5_11.25': 2154, 'G#5_110.75': 2155, 'G#5_114.5': 2156, 'G#5_12.5': 2157, 'G#5_13.0': 2158, 'G#5_14.5': 2159, 'G#5_14/3': 2160, 'G#5_15.75': 2161, 'G#5_16.0': 2162, 'G#5_187.75': 2163, 'G#5_2.0': 2164, 'G#5_2.5': 2165, 'G#5_20.0': 2166, 'G#5_26/3': 2167, 'G#5_3.0': 2168, 'G#5_30.0': 2169, 'G#5_33.5': 2170, 'G#5_35.5': 2171, 'G#5_38.5': 2172, 'G#5_4.0': 2173, 'G#5_4.25': 2174, 'G#5_4.5': 2175, 'G#5_47.5': 2176, 'G#5_5.0': 2177, 'G#5_5/3': 2178, 'G#5_55.75': 2179, 'G#5_62/3': 2180, 'G#5_7.75': 2181, 'G#5_76.0': 2182, 'G#5_8.5': 2183, 'G#6_0.25': 2184, 'G1_0.0': 2185, 'G1_0.25': 2186, 'G1_0.5': 2187, 'G1_1.0': 2188, 'G1_11.5': 2189, 'G1_13.0': 2190, 'G1_2.5': 2191, 'G2_0.0': 2192, 'G2_0.25': 2193, 'G2_0.5': 2194, 'G2_0.75': 2195, 'G2_1.0': 2196, 'G2_1.25': 2197, 'G2_1.5': 2198, 'G2_1/3': 2199, 'G2_13.5': 2200, 'G2_2.0': 2201, 'G2_2.25': 2202, 'G2_2.5': 2203, 'G2_3.0': 2204, 'G2_4.0': 2205, 'G2_5.0': 2206, 'G2_5.25': 2207, 'G2_53.0': 2208, 'G2_6.0': 2209, 'G2_6.25': 2210, 'G2_8.0': 2211, 'G2_9.25': 2212, 'G3_0.0': 2213, 'G3_0.25': 2214, 'G3_0.5': 2215, 'G3_0.75': 2216, 'G3_1.0': 2217, 'G3_1.25': 2218, 'G3_1.5': 2219, 'G3_1.75': 2220, 'G3_1/3': 2221, 'G3_12.25': 2222, 'G3_120.25': 2223, 'G3_13.75': 2224, 'G3_182/3': 2225, 'G3_2.0': 2226, 'G3_2.25': 2227, 'G3_2.5': 2228, 'G3_2.75': 2229, 'G3_20.5': 2230, 'G3_214.5': 2231, 'G3_26.25': 2232, 'G3_267.0': 2233, 'G3_27.0': 2234, 'G3_3.0': 2235, 'G3_3.5': 2236, 'G3_3.75': 2237, 'G3_4.0': 2238, 'G3_4.25': 2239, 'G3_4.75': 2240, 'G3_449/3': 2241, 'G3_49.5': 2242, 'G3_5.0': 2243, 'G3_5.75': 2244, 'G3_5/3': 2245, 'G3_56.25': 2246, 'G3_6.0': 2247, 'G3_7.0': 2248, 'G3_8.75': 2249, 'G3_8/3': 2250, 'G3_81.5': 2251, 'G3_82.5': 2252, 'G3_89.25': 2253, 'G3_9.0': 2254, 'G3_9.25': 2255, 'G3_91.0': 2256, 'G4_0.0': 2257, 'G4_0.25': 2258, 'G4_0.5': 2259, 'G4_0.75': 2260, 'G4_1.0': 2261, 'G4_1.25': 2262, 'G4_1.5': 2263, 'G4_1.75': 2264, 'G4_1/3': 2265, 'G4_10.0': 2266, 'G4_10.5': 2267, 'G4_10.75': 2268, 'G4_10/3': 2269, 'G4_11.0': 2270, 'G4_11.25': 2271, 'G4_11/3': 2272, 'G4_12.0': 2273, 'G4_12.25': 2274, 'G4_12.5': 2275, 'G4_13.25': 2276, 'G4_13.75': 2277, 'G4_14.0': 2278, 'G4_16.0': 2279, 'G4_16.25': 2280, 'G4_18.0': 2281, 'G4_19.0': 2282, 'G4_195.25': 2283, 'G4_2.0': 2284, 'G4_2.25': 2285, 'G4_2.5': 2286, 'G4_2.75': 2287, 'G4_2/3': 2288, 'G4_20/3': 2289, 'G4_22.25': 2290, 'G4_23.25': 2291, 'G4_26.0': 2292, 'G4_27.5': 2293, 'G4_28.25': 2294, 'G4_3.0': 2295, 'G4_3.25': 2296, 'G4_3.5': 2297, 'G4_3.75': 2298, 'G4_36.0': 2299, 'G4_37.75': 2300, 'G4_4.0': 2301, 'G4_4.25': 2302, 'G4_4.5': 2303, 'G4_4.75': 2304, 'G4_4/3': 2305, 'G4_41/3': 2306, 'G4_46.25': 2307, 'G4_5.0': 2308, 'G4_5.25': 2309, 'G4_5.5': 2310, 'G4_5.75': 2311, 'G4_5/3': 2312, 'G4_6.0': 2313, 'G4_6.25': 2314, 'G4_6.5': 2315, 'G4_6.75': 2316, 'G4_7.0': 2317, 'G4_7.25': 2318, 'G4_7.5': 2319, 'G4_8.0': 2320, 'G4_8.25': 2321, 'G4_87.0': 2322, 'G4_9.0': 2323, 'G4_9.5': 2324, 'G5_0.0': 2325, 'G5_0.25': 2326, 'G5_0.5': 2327, 'G5_0.75': 2328, 'G5_1.0': 2329, 'G5_1.25': 2330, 'G5_1.5': 2331, 'G5_1.75': 2332, 'G5_1/3': 2333, 'G5_10.0': 2334, 'G5_10.75': 2335, 'G5_10/3': 2336, 'G5_11.0': 2337, 'G5_11.25': 2338, 'G5_11.5': 2339, 'G5_11/3': 2340, 'G5_12.0': 2341, 'G5_12.75': 2342, 'G5_13.5': 2343, 'G5_13.75': 2344, 'G5_13/3': 2345, 'G5_14.25': 2346, 'G5_14.5': 2347, 'G5_16.0': 2348, 'G5_16.25': 2349, 'G5_16.5': 2350, 'G5_18.25': 2351, 'G5_19/3': 2352, 'G5_2.0': 2353, 'G5_2.25': 2354, 'G5_2.5': 2355, 'G5_2.75': 2356, 'G5_2/3': 2357, 'G5_24.0': 2358, 'G5_25.5': 2359, 'G5_29.5': 2360, 'G5_3.0': 2361, 'G5_3.25': 2362, 'G5_3.5': 2363, 'G5_3.75': 2364, 'G5_38.75': 2365, 'G5_4.0': 2366, 'G5_4.25': 2367, 'G5_4.5': 2368, 'G5_4.75': 2369, 'G5_4/3': 2370, 'G5_40.25': 2371, 'G5_41.25': 2372, 'G5_5.0': 2373, 'G5_5.25': 2374, 'G5_5.5': 2375, 'G5_5.75': 2376, 'G5_5/3': 2377, 'G5_6.0': 2378, 'G5_6.25': 2379, 'G5_6.5': 2380, 'G5_6.75': 2381, 'G5_7.0': 2382, 'G5_7.5': 2383, 'G5_7.75': 2384, 'G5_7/3': 2385, 'G5_8.0': 2386, 'G5_8.25': 2387, 'G5_8.75': 2388, 'G5_8/3': 2389, 'G5_9.75': 2390, 'G6_0.25': 2391, 'G6_0.5': 2392, 'G6_1.0': 2393, 'G6_1.25': 2394, 'G6_1.5': 2395, 'G6_1.75': 2396, 'G6_10.5': 2397, 'G6_12.75': 2398, 'G6_2.0': 2399, 'G6_2.5': 2400, 'G6_29.5': 2401, 'G6_3.0': 2402, 'G6_3.5': 2403, 'G6_4.0': 2404, 'G6_84.0': 2405, 'G6_9.75': 2406, 'G6_99.5': 2407}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B4_9.5\n",
      "0.5\n",
      "C5_3.0\n",
      "D5_5.25\n",
      "0.5\n",
      "A5_0.25\n",
      "0.5\n",
      "0.4\n",
      "B4_0.25\n",
      "E4_5.25\n",
      "C5_0.25\n",
      "B5_0.25\n",
      "E3_0.25\n",
      "C5_0.25\n",
      "G4_0.25\n",
      "E5_0.25\n",
      "C5_1.0\n",
      "G4_0.5\n",
      "G5_0.25\n",
      "A5_0.25\n",
      "G4_0.25\n",
      "F5_0.25\n",
      "E5_0.25\n",
      "D5_1/3\n",
      "B3_1.0\n",
      "E5_0.5\n",
      "D5_0.25\n",
      "B3_0.25\n",
      "G3_0.5\n",
      "B4_0.25\n",
      "D3_0.25\n",
      "B3_0.25\n",
      "G3_0.25\n",
      "G3_0.25\n",
      "0.4\n",
      "G4_0.25\n",
      "A5_0.25\n",
      "G5_0.5\n",
      "11.2\n",
      "C6_0.25\n",
      "E5_0.25\n",
      "G5_0.25\n",
      "E5_0.25\n",
      "F5_0.25\n",
      "D5_0.25\n",
      "5.9\n",
      "B4_0.25\n",
      "G4_0.25\n",
      "D5_0.25\n",
      "A3_1.0\n",
      "G4_0.25\n",
      "B4_0.25\n",
      "A4_0.25\n",
      "G3_0.5\n",
      "C5_0.5\n",
      "F#4_1.0\n",
      "G4_0.25\n",
      "E4_0.25\n",
      "B3_0.25\n",
      "G4_0.25\n",
      "D5_0.25\n",
      "C5_0.25\n",
      "A3_0.5\n",
      "D5_0.25\n",
      "B4_0.25\n",
      "G3_0.25\n",
      "F4_0.5\n",
      "G4_0.5\n",
      "G5_0.25\n",
      "E4_0.25\n",
      "E5_0.25\n",
      "G4_0.25\n",
      "C6_1.0\n",
      "E4_0.25\n",
      "A4_0.25\n",
      "C5_0.5\n",
      "F4_0.25\n",
      "A4_0.25\n",
      "A4_0.25\n",
      "C#3_1.0\n",
      "G4_0.5\n",
      "E4_0.25\n",
      "C5_0.25\n",
      "C4_0.25\n",
      "E4_0.25\n",
      "G3_0.25\n",
      "C4_0.25\n",
      "C2_0.25\n",
      "E2_0.25\n",
      "E3_0.25\n",
      "E4_0.25\n",
      "E3_0.25\n",
      "E-5_0.25\n",
      "C5_2.0\n",
      "C4_0.25\n",
      "E4_0.25\n",
      "E5_0.25\n",
      "11.2\n",
      "C2_0.5\n",
      "E5_0.25\n"
     ]
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "def create_midi(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    for pattern in prediction_output:\n",
    "        if ('_' not in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            offset += 0.5\n",
    "        else:\n",
    "            new_note = note.Note(pattern[0:pattern.find('_')],quarterLength=float(Fraction(pattern[pattern.find('_')+1:])))\n",
    "            new_note.offset = offset\n",
    "            #print(offset)\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "            offset += float(Fraction(pattern[pattern.find('_')+1:]))\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='test_output.mid')\n",
    "    \n",
    "generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate music by covering top x probabilities in the prediction array, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "    prediction_outputA=[]\n",
    "    prediction_outputB=[]\n",
    "\n",
    "    #x=0\n",
    "    for note_index in range(100):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        \n",
    "        ### Copy the line below from your above implementation.\n",
    "        prediction = model.predict(prediction_input)\n",
    "        top5arg = np.argpartition(-prediction[0], 20)\n",
    "        top5_args = top5arg[:20]    \n",
    "        top5 = np.partition(-prediction[0], 20)\n",
    "        top5_result = -top5[:20]\n",
    "        index=random.choices(top5_args,top5_result)\n",
    "        '''index=random.choices(top5_args,top5_result)\n",
    "        prediction = model.predict(prediction_input)\n",
    "        \n",
    "        #print(type(index))\n",
    "        index = random.choices(np.arange(len(int_to_note)),prediction[0])'''\n",
    "        print(int_to_note[index[0]])\n",
    "        result = int_to_note[index[0]]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index[0])\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        \n",
    "\n",
    "    \n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate two sections of music by using top 5 probabilities in the prediction array and top 15 probabilities in the prediction array respectively. And then parse the two section in ABA form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Starts the melody by picking a random sequence from the input as a starting point\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "    prediction_outputA=[]\n",
    "    prediction_outputB=[]\n",
    "\n",
    "    #x=0\n",
    "    for note_index in range(50):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        \n",
    "        ### Copy the line below from your above implementation.\n",
    "        prediction = model.predict(prediction_input)\n",
    "        \n",
    "        top5arg = np.argpartition(-prediction[0], 5)\n",
    "        top5_args = top5arg[:5]\n",
    "        #print(top5_args)\n",
    "        \n",
    "        top5 = np.partition(-prediction[0], 5)\n",
    "        top5_result = -top5[:5]\n",
    "        #print(top5_result)\n",
    "\n",
    "        index=random.choices(top5_args,top5_result)\n",
    "        #print(type(index))\n",
    "        #index = random.choices(np.arange(len(int_to_note)),prediction[0])\n",
    "        print(int_to_note[index[0]])\n",
    "        result = int_to_note[index[0]]\n",
    "        prediction_outputA.append(result)\n",
    "\n",
    "        pattern.append(index[0])\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        \n",
    "    for note_index in range(25):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        \n",
    "        ### Copy the line below from your above implementation.\n",
    "        prediction = model.predict(prediction_input)\n",
    "        \n",
    "        top5arg = np.argpartition(-prediction[0], 15)\n",
    "        top5_args = top5arg[:15]\n",
    "        #print(top5_args)\n",
    "        \n",
    "        top5 = np.partition(-prediction[0], 15)\n",
    "        top5_result = -top5[:15]\n",
    "        #print(top5_result)\n",
    "\n",
    "        index=random.choices(top5_args,top5_result)\n",
    "        #print(type(index))\n",
    "        #index = random.choices(np.arange(len(int_to_note)),prediction[0])\n",
    "        print(int_to_note[index[0]])\n",
    "        result = int_to_note[index[0]]\n",
    "        prediction_outputB.append(result)\n",
    "\n",
    "        pattern.append(index[0])\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "    prediction_output=prediction_outputA+prediction_outputB+prediction_outputA\n",
    "    \n",
    "    return prediction_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
